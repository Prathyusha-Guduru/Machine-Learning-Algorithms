{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3wgc1nSID9j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "c1b0pPXnEF7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "    def __init__(self, predicted_class):\n",
        "        self.feature_index = 0\n",
        "        self.threshold = 0\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.info_gain = 0\n",
        "\n",
        "        # for the leaf node, majority class of the leaf node (predicted class)\n",
        "        self.value = 0"
      ],
      "metadata": {
        "id": "jVE5_XLmELeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gini_impurity(y):\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    p = counts / len(y)\n",
        "    gini = 1 - np.sum(p**2)\n",
        "    return gini"
      ],
      "metadata": {
        "id": "gqmofeH8EqI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_split(X,y):\n",
        "  best_gini = float('inf')\n",
        "  best_feature, best_threshold = None, None\n",
        "\n",
        "  for feature in range(X.shape[1]):\n",
        "    thresholds = np.unique(X[:,feature])\n",
        "    for threshold in thresholds:\n",
        "      left_indices = X[:, feature] <= threshold\n",
        "      right_indices = X[:, feature] > threshold\n",
        "\n",
        "      if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
        "        continue\n",
        "\n",
        "      left_gini = get_gini_impurity(y[left_indices])\n",
        "      right_gini = get_gini_impurity(y[right_indices])\n",
        "      gini = (np.sum(left_indices) * left_gini + np.sum(right_indices) * right_gini) / len(y)\n",
        "\n",
        "      if gini < best_gini:\n",
        "        best_gini = gini\n",
        "        best_feature = feature\n",
        "        best_threshold = threshold\n",
        "\n",
        "  return best_feature, best_threshold"
      ],
      "metadata": {
        "id": "5I-nguzULhye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(X, y, depth=0, max_depth=5, min_samples_split=2):\n",
        "    n_samples, n_features = X.shape\n",
        "    n_classes = len(np.unique(y))\n",
        "\n",
        "    # stopping criteria\n",
        "    if depth >= max_depth or n_samples < min_samples_split or n_classes == 1:\n",
        "        return Node(np.argmax(np.bincount(y)))\n",
        "\n",
        "    best_feature, best_threshold = find_best_split(X, y)\n",
        "    left_indices = X[:, best_feature] <= best_threshold\n",
        "    right_indices = X[:, best_feature] > best_threshold\n",
        "\n",
        "    left_child = build_tree(X[left_indices], y[left_indices], depth + 1, max_depth, min_samples_split)\n",
        "    right_child = build_tree(X[right_indices], y[right_indices], depth + 1, max_depth, min_samples_split)\n",
        "\n",
        "    return Node(feature=best_feature, threshold = best_threshold, left = left_child, right = right_child)"
      ],
      "metadata": {
        "id": "QWdFR5p9OguE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(node, X):\n",
        "  if node.value is not None:\n",
        "    return node.value\n",
        "\n",
        "  if X[node.feature_index] <= node.threshold:\n",
        "    return predict(node.left, X)\n",
        "  else:\n",
        "    return predict(node.right, X)"
      ],
      "metadata": {
        "id": "2z2qsVPMVPL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "  def __init__(self, max_depth=5, min_samples_split=2):\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.root = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.root = build_tree(X, y, self.max_depth, self.min_samples_split)\n",
        "\n",
        "  def predict(self, X):\n",
        "    return [predict(self.root, x) for x in X]\n"
      ],
      "metadata": {
        "id": "PhRVAzj2WBQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Split data\n",
        "\n",
        "tree = DecisionTree(max_depth=3)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "predictions = tree.predict(X_test)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CALxByuzWduF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')  # For multi-class\n",
        "recall = recall_score(y_test, predictions, average='weighted')      # For multi-class\n",
        "f1 = f1_score(y_test, predictions, average='weighted')            # For multi-class\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "SgsQ0a4eWlPR",
        "outputId": "76d1c665-03ad-4cf5-888c-e1d021bbc66b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4222222222222222\n",
            "Precision: 0.1782716049382716\n",
            "Recall: 0.4222222222222222\n",
            "F1-Score: 0.25069444444444444\n",
            "Confusion Matrix:\n",
            "[[19  0  0]\n",
            " [13  0  0]\n",
            " [13  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}